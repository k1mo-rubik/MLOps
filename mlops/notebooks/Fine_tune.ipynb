{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwUXXKi4Q0aA"
   },
   "source": [
    "# Использование предобученных моделей\n",
    "\n",
    "Задание: собрать датасет и использовать перенос обучения для решения задачи классификации.\n",
    "\n",
    "## Порядок выполнения\n",
    "\n",
    "1. Скачать изображения для создания датасета. Как структурировать папки подсмотрите в работе по ConvNet в датасете с Симпсонами;\n",
    "1. Подготовить transforms, DataSet и DataLoader;\n",
    "1. Выбрать одну из моделей в библиотеке timm;\n",
    "1. Использовать на этой модели прием выделения признаков;\n",
    "1. Использовать на этой модели прием дообучения (fine-tune);\n",
    "1. Оценить результаты лучшей модели на тестовой выборке.\n",
    "\n",
    "## Источники\n",
    "\n",
    "1. [Туториал от Pytorch](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
    "1. [GitHub pytorch-image-models](https://github.com/huggingface/pytorch-image-models)\n",
    "1. [Извлечение признаков](https://huggingface.co/docs/timm/feature_extraction)\n",
    "1. [Which image models are best?](https://www.kaggle.com/code/jhoward/which-image-models-are-best)\n",
    "1. [Pytorch Image Models (timm)](https://timm.fast.ai/)\n",
    "1. [huggingface docs timm](https://huggingface.co/docs/hub/timm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmTSr178giM1"
   },
   "source": [
    "## Создание датасета\n",
    "\n",
    "В этом задании вам надо собрать собственный датасет из изображений. В нем должно быть минимум 30 изображений для каждого класса. Количество классов не менее 2. Тематику датасета вы выбираете самостоятельно.\n",
    "\n",
    "Далее в этом разделе приведен пример кода, который помогает скачать изображения по запросу на гугл диск. Вы можете решить эту задачу другими удобными для вас способами, в том числе и вручную.\n",
    "\n",
    "Если вы работаете с локальной средой, то код из примера придется модифицировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YiZ5ZEhvk2E7"
   },
   "outputs": [],
   "source": [
    "# Установка пакета для работы с API поисковика DuckDuckGo\n",
    "\n",
    "!pip install -U duckduckgo_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SYOLkDFCkO4d"
   },
   "outputs": [],
   "source": [
    "from duckduckgo_search import DDGS  # импотр модуля\n",
    "\n",
    "with DDGS() as ddgs:\n",
    "    ddgs_images_gen = ddgs.images(\n",
    "      'owl',  # пример получения изображений по запросу 'owl'\n",
    "      region=\"wt-wt\",\n",
    "      size=\"Medium\",\n",
    "      type_image=\"photo\",\n",
    "      max_results=20,  # максимальное количество изображений в ответе\n",
    "    )\n",
    "    with open('owl.txt', 'w') as f:  # пишем в файл полученные ссылки на изображения для скачивания\n",
    "      for r in ddgs_images_gen:\n",
    "        f.write(f\"{r['image']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PxV4BCm3JgcY"
   },
   "outputs": [],
   "source": [
    "# монтируем гугл диск к среде, чтобы можно было записывать и считывать изображения\n",
    "# в постоянное хранилище на гугл диске. Колаб попросит предоставить доступ.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zA2GpDcoI1PC"
   },
   "outputs": [],
   "source": [
    "# пример создания папки dataset в корне вашего гугл диска\n",
    "!mkdir \"/content/drive/My Drive/dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MbxX8faBKssC"
   },
   "outputs": [],
   "source": [
    "# можно посмотреть содержимое файла со ссылками\n",
    "!cat owl.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tjey4-V1ORpU"
   },
   "outputs": [],
   "source": [
    "# утилита wget построчно читает файл owl.txt и скачивает по URL файлы в папку,\n",
    "# указанную после флага -P. --random-wait добавляет случайные интервалы между запросами,\n",
    "# чтобы снизить вероятность блокировки\n",
    "\n",
    "!wget -i owl.txt --random-wait -P \"/content/drive/My Drive/dataset/owl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZnskrdTPWLpg"
   },
   "source": [
    "### Ответы по датасету (макс. 20 баллов)\n",
    "\n",
    "В результате работы по этому разделу у вас должен получиться датасет. Проверьте что все скачанные изображения открываются и удалите поврежденные файлы. Изображения стоит разделить в папках на train и test и примерном соотношении 80 и 20%.\n",
    "\n",
    "Доступ к вашему датасету потребуется открыть. Если вы скачивали изображения локально, то их надо будет выгрузить на гугл или яндекс диск.\n",
    "\n",
    "**Ссылка на ваш датасет - https://**\n",
    "\n",
    "**Описание вашего датасета:**\n",
    "\n",
    "* Общее описание решаемой задачи:\n",
    "* Количество классов:\n",
    "* Имена классов:\n",
    "* Количество изображений в каждом классе в обучающей и тестовой выборках\n",
    "\n",
    "---\n",
    "\n",
    "Ваш ответ:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qe89rdJOXzL_"
   },
   "source": [
    "## Импортирование модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aK02waSfXyiM"
   },
   "outputs": [],
   "source": [
    "# по необходимости добавляйте свои модули\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUxmE5qwX3dl"
   },
   "outputs": [],
   "source": [
    "# Использование GPU по желанию\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "  print('Работаем на GPU')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "  print('Работаем на CPU')\n",
    "\n",
    "# Не забывайте про .to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCPzXCA8golE"
   },
   "source": [
    "## Выбор модели из timm\n",
    "\n",
    "В источниках к заданию, вы найдете список моделей, который выложен на github и [сравнение части моделей из timm](https://www.kaggle.com/code/jhoward/which-image-models-are-best). Вам необходимо остановить свой выбор на одной из них. В списке моделей на github есть ссылки на статьи о них, где можно найти информацию на каком датасете они были обучены.\n",
    "\n",
    "Если вы работаете с фотографиями выбор можно остановить на одной из:\n",
    "1. MobileNet,\n",
    "1. VGG,\n",
    "1. ResNet,\n",
    "1. Xception.\n",
    "\n",
    "По желанию можете попробовать несколько и сравнить.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMjdZR_2qaIN"
   },
   "outputs": [],
   "source": [
    "# сначала требуется установить сам модуль timm\n",
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Z1C_9kkohcR"
   },
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xlbdL9Y6b0aU"
   },
   "outputs": [],
   "source": [
    "# вывод списка моделей содержащих *resnet* и предобученных\n",
    "# timm.list_models(\"*resnet*\", pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shzcz96tps43"
   },
   "outputs": [],
   "source": [
    "# в качестве первого аргумента укажите имя выбранной модели\n",
    "# и не забудьте указать, предобученный вариант (pretrained)\n",
    "pretrained_model = timm.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0npAa7yq1sY"
   },
   "outputs": [],
   "source": [
    "# Вывод архитектуры модели\n",
    "print(pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qq4f_jxjmQom"
   },
   "source": [
    "В описании архитектуры модели в выводе предыдущей ячейки, найдите два новых модуля (Conv2d, ReLU вы уже знаете) и добавьте их описание. (макс. 15 баллов)\n",
    "\n",
    "**Ваш ответ:**\n",
    "\n",
    "1. Модуль ___ - делает ...\n",
    "1. Модуль ___ - делает ...\n",
    "\n",
    "**Почему решили выбрать именно эту модель?** (макс. 5 баллов)\n",
    "\n",
    "Ваш ответ:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNFhKD6Y1-_1"
   },
   "source": [
    "## Создание Dataset и DataLoader\n",
    "\n",
    "По аналогии с прошлыми заданиями нам требуется создать transforms, которые передаются в создаваемый Dataset и из датасета вы создаете DataLoaders.\n",
    "\n",
    "Данных у нас немного, поэтому мы не будем выделять валидационную часть.\n",
    "\n",
    "При создании transforms помните, что модель ожидает на вход тензор определенной размерности. В [описание моделей](https://paperswithcode.com/lib/timm), вы можете найти датасет, на котором обучалась модель и есть описание размера изображений.\n",
    "\n",
    "Для работы вам пригодится:\n",
    "\n",
    "- v2.ToImage()\n",
    "- v2.Resize() или v2.RandomResizedCrop() - размер изображения после кадрирования, должен быть равен размеру ожидаемому на ходе предобученной модели.\n",
    "- v2.RandomRotation()\n",
    "- v2.RandomHorizontalFlip()\n",
    "- v2.ToDtype()\n",
    "\n",
    "[Описания в документации](https://pytorch.org/vision/stable/transforms.html#v2-api-reference-recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gw2ron_q4phD"
   },
   "outputs": [],
   "source": [
    "# transforms = v2.Compose([]) помните что для обучения и теста нужен разный набор преобразований\n",
    "\n",
    "# train_dataset = ImageFolder(root=\"./data/train\", transform=transforms)\n",
    "# test_dataset = ImageFolder(root=\"./data/train\", transform=transforms)\n",
    "\n",
    "#\n",
    "# Визуализируйте образцы чтобы убедиться, что train_dataset создан корректно\n",
    "# Например используя, make_grid\n",
    "# inputs, classes = next(iter(dataloader))\n",
    "# out = torchvision.utils.make_grid(inputs)\n",
    "# imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNGKdOjq8GqI"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Ваш код\n",
    "#\n",
    "\n",
    "# train_loader = DataLoader()\n",
    "# test_loader = DataLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsJ75cVUAxJF"
   },
   "source": [
    "**Почему выбрали именно такие преобразования (transforms) для данных?** (макс. 10 баллов)\n",
    "\n",
    "Ваш ответ:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JONugIsAAasx"
   },
   "source": [
    "## Прием извлечения признаков\n",
    "\n",
    "Этот прием может использоваться как сам по себе, так и быть предварительным этапом для дообучения.\n",
    "\n",
    "Он заключается в том, что мы заменяем полносвязную часть модели (head/голову) на свою с учетом размерностей выходных данных из сверточной части и количеством классов в текущей задаче. Перед обучением требуется \"заморозить\" параметры сверточных слоев.\n",
    "\n",
    "**Почему требуется \"заморозка\" параметров?** (макс. 10 баллов)\n",
    "\n",
    "Ваш ответ:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5PTKg9_Eo-T"
   },
   "source": [
    "У модели вы можете использовать метод .parameters(), он возвращает итерируемый объект с параметрами вашей модели. Вы можете их перебрать и отключить необходимость расчета градиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7tlFjMgEssT_"
   },
   "outputs": [],
   "source": [
    "# \"Замораживаем\" веса\n",
    "# for param in ___:\n",
    "    #param...\n",
    "\n",
    "# Заменяем \"голову\"\n",
    "# .fc для вашей модели может иметь другое имя\n",
    "# В nn.Sequential добавьте 1-2 скрытых слоя (nn.Linear, nn.ReLU)\n",
    "pretrained_model.fc = nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9-NFp-9Hte_"
   },
   "outputs": [],
   "source": [
    "loss_fn =\n",
    "optimizer ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQgDHSuxIfnZ"
   },
   "source": [
    "В этой работе также рассмотрим применение планировщика для изменения скорости обучения. Ранее у вас скорость обучения была константой, теперь же в процессе обучения каждые n эпох будем ее снижать.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yvg32u5YIdIE"
   },
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "scheduler = lr_scheduler.StepLR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDB-AUNYGZri"
   },
   "source": [
    "### Обучение и тестирование\n",
    "\n",
    "Несколько эпох обучите модель в таком состоянии. Для обучения используйте уже знакомый вам цикл с эпохами и перебором dataloader, но к нему в цикл эпох требуется добавить шаг планировщика scheduler.step().\n",
    "\n",
    "Не забывайте переключать режимы моделей (pretrained_model.train(), pretrained_model.eval()), так как теперь в них может быть пакетная нормализация и используйте контекст torch.no_grad() при проверке модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0WTKo4ycADXb"
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "  for images, labels in loader:\n",
    "\n",
    "  #\n",
    "  # Ваш код\n",
    "  #\n",
    "\n",
    "  scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhvSOSx4Mfak"
   },
   "source": [
    "## Прием дообучения\n",
    "\n",
    "Чтобы дообучить модель, требуется разморозить параметры модели. Для упрощения можете разморозить все параметры модели, но более правильно будет разморозить параметры 1-2 последних слоев и оптимизировать их, и наиболее сложный вариант разморозить больше 2 слоев, но использовать сниженные скорости обучения для более ранних слоев модели - [TORCH.OPTIM](https://pytorch.org/docs/stable/optim.html#per-parameter-options)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJEHBqxjUko9"
   },
   "outputs": [],
   "source": [
    "# Первый вариант\n",
    "# for param in ___:\n",
    "    #param...\n",
    "\n",
    "# Второй вариант\n",
    "# model.blocks[-n:].requires_grad_(True)\n",
    "\n",
    "# Третий вариант\n",
    "# model.blocks[-n:].requires_grad_(True)\n",
    "# optim.SGD([\n",
    "#                 {'params': model.base.parameters()},\n",
    "#                 {'params': model.classifier.parameters(), 'lr': 1e-3}\n",
    "#             ], lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSg0kXIvjJQt"
   },
   "outputs": [],
   "source": [
    "# Новый набор объектов\n",
    "\n",
    "loss_fn =\n",
    "optimizer =\n",
    "scheduler ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uTvl1OTKTbMy"
   },
   "outputs": [],
   "source": [
    "# Новый цикл обучения\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for images, labels in loader:\n",
    "\n",
    "  #\n",
    "  # Ваш код\n",
    "  #\n",
    "\n",
    "  scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9cyD82JQo4L"
   },
   "source": [
    "Скачайте одно новое изображение, которое можно отнести к одному из ваших классов, и классифицируйте его с помощью полученной модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hN1v8bKnTGsD"
   },
   "source": [
    "## Финал\n",
    "\n",
    "Осталось попробовать модель на случайном изображении и ответить на вопросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0hNpPA7JQoB7"
   },
   "outputs": [],
   "source": [
    "# import PIL\n",
    "# img_file = \"./robot_image.jpg\"\n",
    "# img = PIL.Image.open(img_file)\n",
    "# img = transforms(img)\n",
    "# img = img.unsqueeze(0)\n",
    "# model.eval()\n",
    "\n",
    "#\n",
    "# Ваш код\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JuBQv3I4Po7l"
   },
   "source": [
    "**Правильно ли модель классифицировала ваше изображение?** (макс. 10 баллов)\n",
    "\n",
    "Ваш ответ:\n",
    "\n",
    "**Какая итоговая точность работы вашей модели на тестовой выборке?** (макс. 10 баллов)\n",
    "\n",
    "Ваш ответ:\n",
    "\n",
    "**Чем отличается прием извлечения признаков от дообучения?** (макс. 20 баллов)\n",
    "\n",
    "Ваш ответ:"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
